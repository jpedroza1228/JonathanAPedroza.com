{
  "hash": "7a77ba2d4b12c3994383ae8033ec1557",
  "result": {
    "markdown": "---\ntitle: \"Bayes Net Pt. 2\" \nsubtitle: |\n  Estimation\nimage: /posts/2024-03-09-bayes-net-part2-estimation/network_playground.jpg\ncategories: [bayesian, bayesian network, bayes net, R, stan, cmdstanr]\ndate: 2024-03-16\n# citation:\n  # url: \nparams:\n  slug: Bayes-Net-part-2\n  date: 2024-03-16\n---\n\n\n**As I am continuing to grow in understanding and conducting bayesian networks, this page and series may change in the future. -JP**\n\n\n::: {.cell}\n\n:::\n\n\n# Appendix (Stan Code Sections Combined)\n\n\n\n::: {.cell}\n\n```{.default .cell-code}\ndata {\n  int<lower=1> J; // # of respondents/students j\n  int<lower=1> I; // # of items i\n  int<lower=1> K; // # of attributes k\n  matrix[J, I] X; // response matrix x\n  matrix[I, K] Q; //Q matrix Q\n}\nparameters {\n  array[I] real<lower=0, upper=1> guess;\n  array[I] real<lower=0, upper=1> no_guess;\n  real<lower=0, upper=1> lambda1;\n  real<lower=0, upper=1> lambda20;\n  real<lower=0, upper=1> lambda21;\n  real<lower=0, upper=1> lambda30;\n  real<lower=0, upper=1> lambda31;\n  real<lower=0, upper=1> lambda40;\n  real<lower=0, upper=1> lambda41;\n  real<lower=0, upper=1> lambda50;\n  real<lower=0, upper=1> lambda51;\n}\ntransformed parameters {\n  array[J] real theta1;\n  array[J] real theta2;\n  array[J] real theta3;\n  array[J] real theta4;\n  array[J] real theta5;\n  matrix[J, I] delta;\n  array[I] real pi;\n  matrix[J, I] log_lik;\n  vector[I] ps_i = rep_vector(0, I); // Initialize ps_i with zeros\n  array[J] real ps_j;\n  \n  for (j in 1 : J) {\n    theta1[j] = lambda1 * 1 + (1 - lambda1) * (1 - 1);\n    theta2[j] = theta1[j] * lambda21 + (1 - theta1[j]) * lambda20;\n    theta3[j] = theta2[j] * lambda31 + (1 - theta2[j]) * lambda30;\n    theta4[j] = theta3[j] * lambda41 + (1 - theta3[j]) * lambda40;\n    theta5[j] = theta4[j] * lambda51 + (1 - theta4[j]) * lambda50;\n    \n    for (i in 1 : I) {\n      delta[j, i] = pow(theta1[j], Q[i, 1]) * pow(theta2[j], Q[i, 2])\n                    * pow(theta3[j], Q[i, 3]) * pow(theta4[j], Q[i, 4])\n                    * pow(theta5[j], Q[i, 5]);\n      \n      pi[i] = pow(guess[i], delta[j, i]) * pow(no_guess[i], 1 - delta[j, i]);\n      \n      log_lik[j, i] = X[j, i] * log(pi[i]) + (1 - X[j, i]) * log(1 - pi[i]);\n      \n      // Accumulate the values of log_lik over items\n      ps_i[i] = ps_i[i] + log_lik[j, i];\n    }\n    // Sum up the log_lik values for each student\n    ps_j[j] = sum(log_lik[j]);\n  }\n}\nmodel {\n  guess ~ beta(5, 25);\n  no_guess ~ beta(25, 5);\n  lambda1 ~ beta(34, 7);\n  lambda20 ~ beta(8, 36);\n  lambda21 ~ beta(36, 8);\n  lambda30 ~ beta(8, 26);\n  lambda31 ~ beta(26, 8);\n  lambda40 ~ beta(22, 28);\n  lambda41 ~ beta(28, 22);\n  lambda50 ~ beta(22, 22);\n  lambda51 ~ beta(22, 22);\n  \n  target += log_sum_exp(ps_j);\n}\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}